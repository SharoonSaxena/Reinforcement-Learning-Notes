{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A k-armed Bandit Problem\n",
    "Consider the following learning problem. You are faced repeatedly with a choice among\n",
    "k di↵erent options, or actions. After each choice you receive a numerical reward chosen\n",
    "from a stationary probability distribution that depends on the action you selected. Your objective is to maximize the expected total reward over some time period, for example,\n",
    "over 1000 action selections, or time steps.\n",
    "\n",
    "\n",
    "<img src=\"images/Screenshot from 2022-06-14 00-31-17.png\" >\n",
    "\n",
    "\n",
    "Here q*(a) is the expected reward *R* when the action a is chosen at time-t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explorationand Exploitation**\n",
    "\n",
    "If you maintain estimates of the action values, then at any time step there is at least\n",
    "one action whose estimated value is greatest. We call these the greedy actions. When you\n",
    "select one of these actions, we say that you are exploiting your current knowledge of the\n",
    "values of the actions. \n",
    "\n",
    "If instead you select one of the nongreedy actions, then we say you\n",
    "are exploring, because this enables you to improve your estimate of the nongreedy action’s\n",
    "value. Exploitation is the right thing to do to maximize the expected reward on the one\n",
    "step, but exploration may produce the greater total reward in the long run. For example,\n",
    "suppose a greedy action’s value is known with certainty, while several other actions are\n",
    "estimated to be nearly as good but with substantial uncertainty. \n",
    "\n",
    "The uncertainty is\n",
    "such that at least one of these other actions probably is actually better than the greedy\n",
    "action, but you don’t know which one. If you have many time steps ahead on which\n",
    "to make action selections, then it may be better to explore the nongreedy actions and\n",
    "discover which of them are better than the greedy action. \n",
    "\n",
    "Reward is lower in the short\n",
    "run, during exploration, but higher in the long run because after you have discovered\n",
    "the better actions, you can exploit them many times. Because it is not possible both to\n",
    "explore and to exploit with any single action selection, one often refers to the “conflict”\n",
    "between exploration and exploitation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action-value Methods\n",
    "\n",
    "<img src=\"images/Screenshot from 2022-06-14 00-39-28.png\">\n",
    "\n",
    "<img src=\"images/Screenshot from 2022-06-14 00-42-51.png\">\n",
    "\n",
    "<img src=\"images/Screenshot from 2022-06-14 00-38-22.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screenshot from 2022-06-14 00-49-36.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking a Non-Stationary Problem\n",
    "\n",
    "<img src=\"images/Screenshot from 2022-06-14 00-56-54.png\">\n",
    "\n",
    "<img src=\"images/Screenshot from 2022-06-14 00-57-16.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimistic Initial Values\n",
    "\n",
    "<img src=\"images/Screenshot from 2022-06-14 20-39-31.png\">\n",
    "\n",
    "<img src=\"images/Screenshot from 2022-06-14 20-39-46.png\">\n",
    "\n",
    "<img src=\"images/Screenshot from 2022-06-14 20-40-44.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upper Confidence Bound\n",
    "\n",
    "<img src=\"images/Screenshot from 2022-06-14 20-43-05.png\">\n",
    "\n",
    "<img src=\"images/Screenshot from 2022-06-14 20-43-51.png\">\n",
    "\n",
    "<img src=\"images/Screenshot from 2022-06-14 20-44-20.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
